<html>





<!-- Mirrored from webpages.eng.wayne.edu/~av8306/aboutme.htm by HTTrack Website Copier/3.x [XR&CO'2007], Wed, 22 Aug 2007 22:35:57 GMT -->

<head>







  <title>research</title>



<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<style type="text/css">
.arial {
	font-family: Arial, Helvetica, sans-serif;
}
</style>
</head>



<body bgcolor="#333333" link="#ff9933" vlink="#cc6633" alink="#ffff00" text="#bed593">

<p align="center"><font color="#ff9933" size="+3" face="Arial, Helvetica, sans-serif"><strong>Research 

Projects</strong></font></p>

<table width="94%" border="0">

  <tr>

    <td colspan="2"><strong><font color="#ff9933" face="Arial, Helvetica, sans-serif"><strong><a href="http://www.cs.bowiestate.edu/sharad/sim/index.html" target="_parent">Modeling 

  and Simulation of Human Behavior in a Multi-Agent Systems for Emergency Response and Decision Making</a></strong></font></strong></td>

  </tr>

  <tr>

    <td><a href="http://www.cs.bowiestate.edu/sharad/sim/index.html"><img src="sim/a3.jpg" width="200" height="120" border="2"></a></td>

    <td><div align="justify"><font face="Arial, Helvetica, sans-serif">The project incorporates 

  development of AvatarSim model that is developed using theoretical background 

  in Artificial Intelligence (AI) and Fuzzy Logic techniques to model an individual&#8217;s 

  behavior as well as group behavior in emergency situations. Experience shows 

  that human behavior is unpredictable when it comes to making decisions in emergencies. 

  This unpredictability is due to human emotional behavior. Human characteristics 

  such as stress, panic, and anger could contribute to a different result than 

  in a calm and panic situation. Fuzzy logic is used to represent the degree of 

  factors such as stress, panic, and anger. The model AvatarSim is developed in 

  Java programming language and can be displayed on a web browser. Future work 

  includes development of self learning adaptive behavior for intelligent agents 

  and development of fuzzy and neuro-fuzzy approach for uncertainty modeling. 

  Also, evaluation of VRML approach for simulation and modeling of agent based 

  human behavior system.</font></div></td>

  </tr>

  <tr>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
  </tr>
  <tr>
    <td colspan="2"><strong><font color="#ff9933" face="Arial, Helvetica, sans-serif"><strong><a href="http://cs.bowiestate.edu/sharad/vrlab/VAPOC.html" target="_new">Data Visualization, Analysis and Prediction of COVID-19 </a></strong></font></strong></td>
  </tr>
  <tr>
    <td><a href="pics/2018/data/Data Visualization 7.png"><img src="vrlab/pics/2018/data/Data Visualization 7.png" width="216" height="135"></a></td>
    <td><div align="justify"><font face="Arial, Helvetica, sans-serif"> The goal of NSF funded VAPOC (Visualization, Analysis and Prediction of COVID-19) project is to find out reasons as to why the black community is disproportionally impacted during the coronavirus pandemic. The VAPOC project combines neural networks predictions with human centric situational awareness and data analytics to provide accurate, timely and scientific strategy in combatting and mitigating the spread of the coronavirus plague in the black community. The project involves development of a visualization and interaction tool to analyze COVID-19 patients' dataset in an immersive and non-immersive environment in accordance with the user's requirements to enhance situational awareness.</font></div></td>
  </tr>
  <tr>
    <td colspan="2">&nbsp;</td>
  </tr>
  <tr>
    <td colspan="2"><strong><a href="vrlab/MegaCity.html" target="_new" class="arial">Megacity: A Collaborative Virtual Reality Environment for Emergency Response, Training, and Decision Making</a></strong></td>
  </tr>
  <tr>
    <td><a href="vrlab/MegaCity.html"><img src="vrlab/pics/2016/megacity/m1.png" width="216" height="135"></a></td>
    <td><div align="justify"><font face="Arial, Helvetica, sans-serif">We have used game creation as a metaphor for creating an experimental setup to study human behavior in a megacity for emergency response, decision-making strategies, and what-if scenarios. Our proposed collaborative VR environment includes both immersive and non-immersive environments. The participant can enter the CVE setup on the cloud and participate in the emergency evacuation drill, which leads to considerable cost advantages over large-scale, real-life exercises. We present two ways for controlling crowd behavior. The first defines rules for agents, and the second provides controls to the users as avatars to navigate in the VR environment as autonomous agents. The novelty of our work lies in modeling behaviors (hostile, non-hostile, selfish, leader-following) for computer-controlled agents so that they can interact with user-controlled agents in a CVE. </font></div></td>
  </tr>
  <tr>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
  </tr>
  <tr>
    <td colspan="2"><strong><a href="vrlab/campusevac.html" target="_new" class="arial">Active Shooter Response and Training for BSU Campus in a Collaborative Virtual Reality Environment (CVE)<span id="Active Shooter Response and Training for BSU Campus in a Collaborative Virtual Reality Environment (CVE)"></span></a></strong> </td>
  </tr>
  <tr>
    <td><a href="vrlab/campusevac.html"><img src="vrlab/pics/2019/activeshooter/sh2.png" width="217" height="133"></a></td>
    <td><div align="justify"><font face="Arial, Helvetica, sans-serif">We have developed a collaborative immersive environment in VR for active shooter response for BSU campus. The BSU university campus CVE environment is designed for corner cave and oculus rift head mounted display to give the user a complete immersive experience of the  campus. Immersive collaborative virtual reality environment also offers a unique way for training in the emergencies for campus safety. The participant can enter the collaborative virtual reality environment setup on the cloud and participate in the evacuation drills which leads to considerable cost advantages over large scale real life exercises. The contribution also lies in our approach to combining computer simulated agents (AI agents) and user-controlled autonomous agents in a collaborative virtual environment for conducting emergency response training for security personnel's. </font></div></td>
  </tr>
  <tr>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
  </tr>
  <tr>
    <td colspan="2"><strong><a href="http://cs.bowiestate.edu/sharad/vrlab/Hololens.html" target="_parent"><font face="Arial, Helvetica, sans-serif">Augmented Reality with Hololens: Building Evacuation   </font></a></strong></td>
  </tr>
  <tr>
    <td><a href="http://cs.bowiestate.edu/sharad/vrlab/Hololens.html" target="_parent"><img src="vrlab/pics/2018/Hololens/20180529_132311.jpg" width="200" height="150"></a><a href="vrlab/arttoolkit.html"></a></td>
    <td><div align="justify"><font face="Arial, Helvetica, sans-serif">Early hands-on experiences with the Microsoft Hololens augmented/mixed reality device have given promising results for building evacuation applications. A range of use cases are tested, including data visualization and immersive data spaces, in-situ visualization of 3D models and full scale architectural form visualization. The Hololens is a remarkable tool for moving from traditional visualization of 3D objects on a 2D screen, to fully experiential 3D visualizations embedded in the real world.
Our Hololens application gives a visual representation of a computer science building in 3D space, allowing people to see where exits are in the building and their current location. It also shows path to the various exits; shortest path to the exist as well as directions to a safe zone. This work comprises an AR application being built to help users evacuate a building. The application was built for Microsoft HoloLens, a device offering users a 3D, holographic view of building floor plans so that they can have a better perspective of the building, making it easier for them to find a way out of the building during the evacuation. Pilot studies were conducted with the system showing its partial success and demonstrated the effectiveness of the application in an emergency evacuation. </font></div></td>
  </tr>
  <tr>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
  </tr>
  <tr>
    <td colspan="2"><strong><a href="http://cs.bowiestate.edu/sharad/vrlab/Patient.html" target="_parent"><font face="Arial, Helvetica, sans-serif">COVID-19 Virtual Reality Instructional (VRI) Training for Improving Quality of Care and Patient Safety </font></a></strong></td>
  </tr>
  <tr>
    <td><a href="vrlab/pics/2016/patient/GameModePhoto3.JPG"><img src="vrlab/pics/2016/patient/GameModePhoto3.JPG" width="216" height="180"></a></td>
    <td><div align="justify"><font face="Arial, Helvetica, sans-serif">Our goal is to develop virtual reality instructional (VRI) modules to train integrated care team members to engage patients from vulnerable populations safely and efficiently. As the COVID-19 pandemic continues unabated, socially vulnerable populations face disproportionate risks as is often the case during public health emergencies. Emerging trends of differential impact on socially vulnerable populations, such as certain racial and ethnic minorities, among others, require urgent attention to improve quality of care and patient safety. This project aims to characterize determinants for improving quality of care and patient safety among vulnerable populations, specifically with a focus on racial and ethnic minorities, and fully incorporate these findings into the creation and development of Virtual Reality Instructional (VRI) training modules geared for integrated care teams to enhance care delivery. </font></div></td>
  </tr>
  <tr>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
  </tr>
  <tr>
    <td colspan="2"><strong><a href="vrlab/MARA2.html" target="_parent"><font face="Arial, Helvetica, sans-serif">Mobile Augmented Reality  Application (MARA) for Building  Evacuation Using Intelligent Signs</font></a></strong></td>
  </tr>
  <tr>
    <td><a href="vrlab/arttoolkit.html"><img src="vrlab/pics/2017/AR/ar11.png" width="200" height="120" border="2"></a></td>
    <td><div align="justify"><font face="Arial, Helvetica, sans-serif"> Motivated by augmented reality's educational use and mobile technology's ubiquitous presence, an Android-based mobile augmented reality application (MARA) was developed to show people how to evacuate the Computer Science Building at Bowie State University. The  application was implemented for Android-based systems using Unity3D and  Vuforia.&nbsp; By featuring intelligent signs  acting as visual aids, it promises to be effective at helping users determine  and visualize the best path to the nearest exit. the  MARA was built as an alternative to live evacuation drills using Unity3d along  with the Vuforia AR Toolkit and the Android SDK. The uniqueness of this  research effort is the inclusion of visual cues, known as intelligent signs, to further assist the user in  evacuating the building. Although, the app has been tested out throughout its  development, a user study will be performed to evaluate its usability and the  effectiveness of the intelligent signs.</font></div></td>
  </tr>
  <tr>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
  </tr>
  <tr>
    <td colspan="2"><a href="vrlab/course.html" target="_parent"><strong><font size="+1" face="Arial, Helvetica, sans-serif">Game-Theme Instructional (GTI) and Virtual Reality Instrctional (VRI) Modules for Teaching and Learning</font></strong></a></td>
  </tr>
  <tr>
    <td><a href="vrlab/pics/g2.gif"><img src="vrlab/pics/g2.gif" width="200" height="150" border="2"></a><a href="FINALPROJECT/courseModule2012/Projects2012_clip_image003.jpg"></a></td>
    <td><div align="justify"><font face="Arial, Helvetica, sans-serif">The aim of this project is to create instructional course curriculum modules with more inquiry based problem-solving activities and hand-on experiences based on Gaming and Virtual Reality. The game theme instructional (GTI) modules endeavor to increase the students interest in learning programming concepts. However, the GTI modules should be usable and likable to include it in a class curriculum. We have incorporated a virtual instructor to help the users learn in the modules. We have evaluated the GTI modules using User Engagement Scale (UES), Theory of Reasoned Action (TRA), and Science Motivation Questionnaire (SMQII) to evaluate usability, likability, and motivation respectively. The result of evaluation shows that the modules are usable, likable, motivational, and engaging.  We have developed VRI modules for arrays, linked list, memory mangament, trees, binary search, stacks, queues, etc.</font></div></td>
  </tr>
  <tr>
    <td colspan="2">&nbsp;</td>
  </tr>
  <tr>
    <td colspan="2"><strong><a href="vrlab/bus.html" target="_parent"><strong><font size="+1" face="Arial, Helvetica, sans-serif">School Bus Evacuation Drills in immersive VR environment using Oculus Touch</font></strong></a></strong></td>
  </tr>
  <tr>
    <td><a href="vrlab/pics/2017/bus/All Fully Functional Exits.JPG"><img src="vrlab/pics/2017/bus/All Fully Functional Exits.JPG" width="217" height="153"></a></td>
    <td><p align="justify"><font face="Arial, Helvetica, sans-serif">Virtual reality experiments with virtual evacuation  drills are necessary to study human behavior under emergency  situations that cannot be evaluated in the real world. The use of collaborative  virtual environments to run virtual evacuation drills for an emergency  evacuation eliminates risk of injury to participants and allows for the testing  of scenarios that could not be tested in real life due to legal issues and  possible health risks to participants. We have developed a collaborative virtual environment (CVE) using Unity 3D gaming engine for performing evacuation drills for a school bus. We have integrated oculus rift touch  to interact in the immersive school bus environment. We have demonstrated the School Bus Evauation Drill demo at <a href="https://usasciencefestival.org/">USA Science Festival for STEM </a>at Walter E. Washington Convention Center, Washington DC on April 7 &amp; 8, 2018. We will conduct user studies for performing evalucation drills in a multi-user school bus environment in both immeresive and non-immersive environment setting. </font></p></td>
  </tr>
  <tr>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
  </tr>
  <tr>
    <td colspan="2"><strong><a href="vrlab/arttoolkit.html" target="_parent"><font face="Arial, Helvetica, sans-serif">M-Evac: Mobile Augmented Reality  Application (MARA) for  Navigation, Learning and Campus Safety </font></a></strong></td>
  </tr>
  <tr>
    <td><a href="arttoolkit.html"><img src="vrlab/pics/2018/AR/Screenshot.png" width="200" height="150" border="2"></a><a href="vrlab/arttoolkit.html"></a></td>
    <td><div align="justify"><font face="Arial, Helvetica, sans-serif">M-Evac  is a AR application that allows you to view the 3D augmented reality scenes. 3D  models are overlaid on the real world as seen through a mobile or computer&rsquo;s  webcam, making them appear to part of the surrounding real environment. M-Evac  uses marker-based camera tracking such that the  3D models appear attached to physical printed markers. We show how the application is able to display a 3D model of the building using markers and web camera. The system gives a visual representation of a  building in 3D space, allowing people to see where exits are in the building through the use of a smart phones and tablets. M-Evac is a Mobile Augmented Reality Application (MARA). The MARA will enale enable policymakers and first-responders to evaluate evacuation strategies and mobile device usage during evacuations. </font></div></td>
  </tr>
  <tr>
    <td colspan="2">&nbsp;</td>
  </tr>
  <tr>
    <td colspan="2"><a href="vrlab/multiagent.html" target="_parent"><strong><font size="+1" face="Arial, Helvetica, sans-serif">Using Genetic Algorithim and Neural Network for learning and adaptive behavior in a goal finding application </font></strong></a></td>
  </tr>
  <tr>
    <td><a href="vrlab/multiagent.html"><img src="vrlab/pics/agent.png" width="219" height="210" border="2"></a></td>
    <td><p align="justify"><font face="Arial, Helvetica, sans-serif">The goal of this project is  combining Genetic  Algorithm (GA) with Neural Networks (NN) to explore how intelligent agents can  look for exits during an evacuation. The agents have the capability to adapt  their behavior in the environment and formulate their response by learning from  the environment. Our approach focuses on modeling individual behavior as well  as group behavior. Individuals constantly adjust their behavior according to  the dynamic factors in the environment. We are developing crowd-modeling and  emergency behavior modeling capability in a goal finding application. This  project examines an intelligent agent-based evacuation that can help plan  emergency evacuations, run numerous event-driven evacuation scenarios, support  research in the areas of human behavior, and model the movement of responders  and security personnel. The result of this simulation was very promising as we  are able to observe the agents use GA and NN to learn how to find the various  exits. We have built a goal finding application using  C# for crowd movement where the agents are shown in different colors. When the  simulation starts the agents have an assigned initial goal. Some of these agents  have a secondary goal that leads them to group together as they move towards  the goal. Crowd simulation involves modeling the environment and human behavior.</font></p></td>
  </tr>
  <tr>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
  </tr>
  <tr>
    <td colspan="2"><a href="dataScience.html" target="_parent"><strong><font size="+1" face="Arial, Helvetica, sans-serif">Data Science and Visualization: Hedonic House Pricing Model using Deep Learning</font></strong></a></td>
  </tr>
  <tr>
    <td><font color="#FFFFFF" face="Arial, Helvetica, sans-serif"><a href="pics/1.png" target="_parent"><img src="pics/1.png" width="217" height="167" border="2"></a></font></td>
    <td><div align="justify"><font face="Arial, Helvetica, sans-serif">This research work focuses on a machine learning algorithmic implementation of the hedonic house pricing theory. The theory relates the market value of a differentiated commodity to its composite attributes. Implementation of the theory was done using deep neural networks and ridge regression learning algorithms. </font><font face="Arial, Helvetica, sans-serif">This work focuses on an algorithmic investigation of the housing market spanning 11 years using the hedonic pricing theory. Hedonikos, is a Greek word for pleasure. Therefore, hedonics-pricing theory shows the relationship between the price of a differentiated commodity and its utility or pleasure. This implies that consumer pays for the pleasure or utility they derive from the purchase of a commodity through its characteristic features. House, laptops, cars etc. are examples of differentiated commodities. Using the hedonic pricing theory, our experiment demonstrated that a deep learning has a superior predictive capability in estimating the value of a real estate property. It also shows that a ridge regression model have interpretability and inferentiality advantage. While deep learning may be preferred in predicting the price of a differentiated commodity like a real estate property, however, ridge regression is more suitable in explaining the concept of utility based on the set of implicit prices of its characteristic features. </font></div></td>
  </tr>
  <tr>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
  </tr>
  <tr>

    <td colspan="2"><strong><font size="+1"><a href="vrlab/multiuser.html" target="_parent"><font face="Arial, Helvetica, sans-serif">Multi</font></a></font></strong><font face="Arial, Helvetica, sans-serif"><a href="vrlab/multiuser.html" target="_parent"><font size="+1"><strong>&#8208;User Virtual Environment (MUVE) in VR for  Airplane Evacuation  Using Gaming Metaphor</strong></font></a></font></td>

  </tr>

  <tr>

    <td><a href="http://www.cs.bowiestate.edu/sharad/vrlab/multiuser.html" target="_parent"><img src="vrlab/pics/image1.jpg" width="200" height="120" border="2"></a><a href="vrlab/multiuser.html" target="_parent"></a></td>

    <td><div align="justify"><font face="Arial, Helvetica, sans-serif">Virtual Reality (VR)  training has been used for training and education for many years in military  and medical fields. We have used game creation  as a metaphor in creating an experimental setup to study evacuation behavior. Our objective is to create an experimental design setup for assessing human behavior in emergency evacuation of an aircraft among a team of players in a game set in a virtual environment. Also, our aim is to create a multi user environment to allow participants in different geographical locations to connect and be able to interact in the VR environment. Our hypothesis is that the &ldquo;sense of presence&rdquo; provided by  the multi-user virtual environment will allow running simulations and  conducting evacuation drills without the cost and risk of injury to live actors.</font></div></td>

  </tr>

  <tr>

    <td colspan="2">&nbsp;</td>

  </tr>

  <tr>

    <td colspan="2">&nbsp;</td>

  </tr>

  <tr>

    <td colspan="2"><strong><strong><a href="vrlab/Subway.html" target="_parent"><font face="Arial, Helvetica, sans-serif">Mult-user Virtual Reality Environment (MUVR) for conducting Subway Evacuation drills using Unity 3D and Oculus Rift</font></a><font face="Arial, Helvetica, sans-serif"><a href="http://www.cs.bowiestate.edu/sharad/vrlab/AirportEvac.html" target="_parent"></a></font></strong></strong></td>

  </tr>

  <tr>

    <td><a href="Subway.html"><img src="vrlab/pics/2014/PICS-subway/crowd.JPG" width="200" height="120" border="0"></a><a href="http://www.cs.bowiestate.edu/sharad/vrlab/AirportEvac.html" target="_parent"></a></td>

    <td><div align="justify"><font face="Arial, Helvetica, sans-serif">People catch the train to get around the city for many reasons, and with so many people using subway trains, emergencies are bound to occur. A virtual multi-user environment can be used to find flaws in evacuation procedure and show passengers a better way to avoid danger in an emergency. Creating a live emergency with real people would be dangerous and unethical. However, creating a virtual emergency with real people is safe and efficient. We have used game creation  as a metaphor in creating an experimental setup to study evacuation behavior in a Virtual Reality Multi-suer Subway Environment.</font></div></td>

  </tr>

  <tr>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
  </tr>

  <tr>
    <td colspan="2"><font size="+1" face="Arial, Helvetica, sans-serif"><strong><a href="vrlab/VRclassroom.html" target="_parent">Virtual Reality Classroom: A Collaborative Educational 
      
      Virtual Learning Environment</a></strong></font></td>
  </tr>
  <tr>
    <td><a href="vrlab/VRclassroom.html"><img src="vrlab/pics/vc01.png" width="200" height="135" border="2"></a><a href="VRclassroom.html"></a></td>
    <td><div align="justify"><font face="Arial, Helvetica, sans-serif">This project presents a Virtual Reality Classroom
      
      that is similar to second life. TheVR environment could 
      
      be used as an actual virtual classroom where  
      
      teachers can interact with students and deliver the lecture. The multi-user virtual 
      
      classroom is developed so that students can interact with 
      
      each other as well as the instructor. Teachers can also use this 
      
      server/client feature for delivering lectures in an online virtual environment. Currently, on  the server side the VR classroom environment consists of   eight classrooms with  two student lounges with distinct individual   textures. On the client side the  user will be able to log into the   server as an avatar of his/her choice through  a drop box provided to   the user.  In the   current system people can navigate the  virtual classroom as a student   or as an instructor  through the use of keyboard inputs. Gesture action is implemented for visual interaction as well as a chat feature for verbal interaction. We have integrated Microsoft XBox Kinect for movement detection of the instructor.</font></div></td>
  </tr>
  <tr>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
  </tr>
  <tr>

    <td><font color="#ff9933" size="+3" face="Arial, Helvetica, sans-serif"><strong>Old Projects</strong></font></td>

    <td>&nbsp;</td>

  </tr>
  <tr>
    <td colspan="2">&nbsp;</td>
  </tr>
  <tr>
    <td colspan="2"><font face="Arial, Helvetica, sans-serif"><strong><a href="vrlab/android.html" target="_parent">Android App for Emergency Response and Surveillance</a></strong></font></td>
  </tr>
  <tr>
    <td><a href="vrlab/pics/ar5.gif"><img src="vrlab/pics/ar5.gif" width="187" height="163" border="2"></a></td>
    <td><div align="justify"><font face="Arial, Helvetica, sans-serif">The goal of this project is to develop an android application for emergency surveillance at BSU by using google latitude and longitude to determine the location of the user. It will provide safety decision making system for a school/university. We are using Eclipse IDE to add the google map with normal and satellite view into the application with a valid API key. We are also combining the geo-location and location manager with the map to get the current location of the user. Currently we are working on tracking multiple users and integrating augemtned reality markers on the campus map.</font></div></td>
  </tr>
  <tr>
    <td colspan="2">&nbsp;</td>
  </tr>
  <tr>
    <td colspan="2"><font face="Arial, Helvetica, sans-serif"><a href="vrlab/OculusRift.html" target="_new"><font size="+1"><strong>Oculus Rift Virtual Campus Tour and Virtual Evacuation Drills of Bowie State University Campus </strong></font></a></font></td>
  </tr>
  <tr>
    <td><a href="vrlab/OculusRift.html" target="_new"><img src="vrlab/pics/2014/occulus/1.JPG" width="200" height="120"></a><a href="http://www.cs.bowiestate.edu/sharad/vrlab/AirportEvac.html" target="_parent"></a></td>
    <td><div align="justify">
      <p><font face="Arial, Helvetica, sans-serif">The use of multi user virtual reality  environment training and virtual tours have been increasingly recognized an as alternative  to traditional real-life tours for university campuses. Our proposed application  shows an immersive collaborative virtual reality environment for performing  virtual online campus tours and evacuation drills using oculus rift head  mounted displays. Immersive collaborative virtual reality environment also offers a  unique way for training in the emergencies for campus safety. The participant  can enter the collaborative virtual reality environment setup on the cloud and  participate in the evacuation drill or a tour which leads to considerable cost  advantages over large scale real life exercises. </font></p>
    </div></td>
  </tr>

  <tr>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
  </tr>
  <tr>

    <td><img src="http://upload.wikimedia.org/wikipedia/commons/8/87/NSF_Logo.PNG" width="102" height="112"></td>

    <td><p><font face="Arial, Helvetica, sans-serif"><strong><a href="vrlab/TIPgrant.html" target="_parent">Targeted   Infusion Project: Development of a Virtual and Augmented Reality Laboratory for Research   and Education </a></strong></font></p>

        <p><font face="Arial, Helvetica, sans-serif"><strong><a href="vrlab/TIPgrant.html" target="_parent"><em>Funded by the National Science Foundation (NSF). Award Number: HRD-1137541, Award Period: 09/15/2011 to 08/31/2014. [ Award Amount: $299,489]</em></a><font size="+1"><a href="traffic.html"><em></em></a></font></strong></font></p></td>

  </tr>

  <tr>

    <td><p>&nbsp;</p>

        <p><a href="vrlab/Screenvtools.png"><img src="vrlab/Screenvtools.png" width="211" height="126" border="0"></a></p></td>

    <td><div align="justify"><font face="Arial, Helvetica, sans-serif">Development of a Virtual   and Augmented Reality Laboratory for Research and Education at Bowie   State University - will enhance the computer science and mathematics   curriculum and increase research opportunities for undergraduate   students by deploying Virtual and Augmented Reality (VAR) as a research   and educational vehicle to immerse students in research and critical   thinking challenges. The students will gain experience by using state-of-the-art VR equipment, software and technologies including 3D Wall, Head Mounted Display (HMD) that allows students to visualize complex data in three dimensional (3D) objects, working in 3D space to solve complex spatial problems, and conducting novel research through course work and research experience in the laboratory.</font></div></td>

  </tr>

  <tr>

    <td>&nbsp;</td>

    <td>&nbsp;</td>

  </tr>

  

  <tr>

    <td>&nbsp;</td>

    <td>&nbsp;</td>

  </tr>

  <tr>

    <td colspan="2"><strong><font color="#ff9933" face="Arial, Helvetica, sans-serif"><strong><a href="http://www.cs.bowiestate.edu/sharad/vrlab/research.html" target="_parent">Virtual 

  Reality Projects</a></strong></font><font size="+1"><a href="Dulles.html"></a></font></strong></td>

  </tr>

  <tr>

    <td><p><a href="http://www.cs.bowiestate.edu/sharad/vrlab/AirportEvac.html" target="_parent"><img src="vrlab/pics/image1.jpg" width="200" height="120" border="2"></a><a href="http://www.cs.bowiestate.edu/sharad/vrlab/traffic.html"></a><a href="FINALPROJECT/DullesAirport/plane.png"></a></p>

        <p><a href="http://www.cs.bowiestate.edu/sharad/vrlab/Dulles.html"><img src="vrlab/FINALPROJECT/DullesAirport/plane.png" width="200" height="110" border="2"></a><a href="FINALPROJECT/DullesAirport/a2.jpg"></a><a href="pics/3.PNG"></a></p></td>

    <td><p><strong><font size="+1"><a href="Dulles.html"></a></font></strong></p>

        <p align="justify"><font face="Arial, Helvetica, sans-serif">The projects  include: Simulation and Evacuation of Dulles 

                  Airport Passengers in Emergency Scenario, Crowd behavior and traffic intersection problem in a Virtual City, Simulating and Modeling of Bowie State University's Library for 

  Navigation, Educational Virtual Learning Environment/ Virtual Professor's Classroom, 

  Battlefield Scenario Simulation, Museum projects, and Evacuation Simulations. The development 

  of virtual reality environment makes it possible for a user to understand and 

  observe multiple paths that an agent would observe during navigation and evacuation. </font></p>

    <p align="justify"><a href="vrlab/navigationbsu.html"><img src="vrlab/pics/l6.jpg" width="190" height="110" border="2"></a> <a href="vrlab/VRclassroom.html"><img src="vrlab/pics/c5.jpg" width="147" height="110" border="2"></a> <a href="http://www.cs.bowiestate.edu/sharad/vrlab/Roviobsu.html"></a><a href="http://www.cs.bowiestate.edu/sharad/vrlab/crowdbsu.html"><img src="vrlab/pics/cc1.jpg" width="200" height="110" border="2"></a><a href="http://www.cs.bowiestate.edu/sharad/mus/Museum.htm"></a><a href="http://www.cs.bowiestate.edu/sharad/vrlab/traffic.html"><img src="vrlab/FINALPROJECT/Traffic/v2.jpg" width="200" height="110" border="2"></a></p></td>

  </tr>

  <tr>

    <td>&nbsp;</td>

    <td>&nbsp;</td>

  </tr>

  <tr>

    <td colspan="2"><font color="#FFFFFF" face="Arial, Helvetica, sans-serif"><strong><font color="#ff9933">Voice FMC: </font><a href="http://www.cs.bowiestate.edu/sharad/voiceFMC/voiceFMC.html"><font color="#ff9933" face="Arial, Helvetica, sans-serif"><strong>Voice Field Medical Card </strong></font></a></strong></font></td>

  </tr>

  <tr>

    <td colspan="2">&nbsp;</td>

  </tr>

  <tr>

    <td><a href="http://www.cs.bowiestate.edu/sharad/voiceFMC/voiceFMC.html"><img src="voiceFMC/voice1.gif" width="214" height="278" border="2"></a></td>

    <td><p align="justify"><font face="Arial, Helvetica, sans-serif">This research is supported by the   United States Army  Medical Research and Material Command (USAMRMC) Acquisition Activity through the Maryland Technology Development Corporation  (TEDCO) Maryland Research and Applied Sciences Consortium (MRASC) Applied  Research and Development Project (ARDP). Industry Partner is  DSbyte Solutions, LLC. The purpose is to develop a computer software  prototype that will automatically create a Field Medical Card based on speech  input provided by a combat medic during combat casualty care.&nbsp; The computer software prototype, given a pre-recorded  battlefield medic speech data, will translate the speech into corresponding  text and use natural language processing (NLP) techniques and external medical  terminology to construct textual meaning where a software algorithm can then  create an electronic DD1380 Field Medical Card (changed to TCCC  Casualty Card). Preliminary speech recognition, speech synthesis, and natural language processing system research shows promise to achieve the desired goals.</font></p></td>

  </tr>

  <tr>

    <td colspan="2">&nbsp;</td>

  </tr>

  

  <tr>

    <td colspan="2"><font face="Arial, Helvetica, sans-serif"><strong><a href="http://www.cs.bowiestate.edu/sharad/vrlab/Roviobsu.html" target="_parent">Rovio 

  Robot for Surveillance in Emergencies</a></strong></font></td>

  </tr>

  <tr>

    <td><a href="http://www.cs.bowiestate.edu/sharad/vrlab/Roviobsu.html"><img src="vrlab/rovio1.jpg" width="200" height="110" border="2"></a></td>

    <td><div align="justify"><font face="Arial, Helvetica, sans-serif">Rovio is a Wi-Fi 
      
      enabled mobile webcam that lets you view and interact with the environment through 
      
      streaming video and audio. There is a need to address the vulnerability and 
      
      assessment plans for evacuation scenarios. It is important to plan ahead by 
      
      targeting groups and identifying specific population. Our research focuses on 
      
      dispatching Rovio to the threat location to collect data and exchange messages 
      
      with other mobile/ static sensors. Our work also focuses on wireless mesh network 
      
      (WSN), intelligent fuzzy interface system, real-time video stream data fusion, 
      
      background modeling and anomaly detection. We are working on developing a surveillance 
      
      application in C# to monitor the static video cameras and dynamic video cameras 
      
      (Rovio). </font></div></td>

  </tr>

  <tr>

    <td>&nbsp;</td>

    <td>&nbsp;</td>

  </tr>

  <tr>

    <td colspan="2"><font color="#ff9933" face="Arial, Helvetica, sans-serif"><strong><em><a href="http://www.cs.bowiestate.edu/sharad/voiceFMC/onlinebackup.html">Online Data Backup System</a></em></strong></font></td>

  </tr>

  <tr>

    <td><font face="Arial, Helvetica, sans-serif"><a href="http://www.cs.bowiestate.edu/sharad/voiceFMC/onlinebackup.html"><img src="voiceFMC/onlinebackup_clip_image002.gif" width="208" height="228" border="2"></a></font></td>

    <td><div align="justify"><font face="Arial, Helvetica, sans-serif">This research was supported by the Thurgood marshal  college funds, TMCF/DOE HBCU technology graduate student award,Year: 2009-2010</font>. <font face="Arial, Helvetica, sans-serif">This project concentrates on developing a new  methodology for the online assessment web applications that could be used while  offline. It is important to retrieve the critical data collected during an  examination without a provision of a backup mechanism. There is a need for an  assessment system that can adapt to work uninterruptedly and without loss of  critical data while there is intermittent internet discontinuity. This project  describes architecture and implementation of online assessment system with  offline capabilities. Online assessment system with offline capabilities will  not interrupt examinee&rsquo;s experience while appearing for an assessment test if  internet connection is not available. A development methodology is designed and  a compliant framework is implemented to enhance online assessment system with  offline capabilities.</font></div></td>

  </tr>

  <tr>

    <td colspan="2">&nbsp;</td>

  </tr>

  <tr>

    <td colspan="2"><font color="#ff9933" face="Arial, Helvetica, sans-serif"><strong><a href="http://www.cs.bowiestate.edu/sharad/vrlab/museumProjects.html" target="_parent">Virtual 

  Reality Museum as a Tool for Learning and Navigation </a></strong></font></td>

  </tr>

  <tr>

    <td><a href="http://www.cs.bowiestate.edu/sharad/mus/Museum.htm"><img src="vrlab/pics/a2.jpg" width="180" height="110" border="2"></a></td>

    <td><div align="justify"><font face="Arial, Helvetica, sans-serif">Virtual Reality (VR) 
      
      is widely acknowledged as an environment with a great potential for learning 
      
      and teaching. The ability of Virtual Reality to explain the principles of design, 
      
      manufacturing and business far surpasses that of books. Virtual environments 
      
      (VE) provide facility for experiential learning by allowing the students to 
      
      explore the VE at their own pace and interact in real time. Game creation can 
      
      be used as a metaphor in creating and using learning resources for early design 
      
      education. The metaphors related to play could be games, explorations, intrinsic 
      
      rewards; and rules and how they can be used in learning games. Students enjoy 
      
      working with virtual worlds and this experience can be highly motivating. Web-based 
      
      environment provides a non-immersive virtual reality experience. Thousands of 
      
    VRML worlds are already available on the Web and the number is increasing daily. </font></div></td>

  </tr>

  <tr>

    <td>&nbsp;</td>

    <td>&nbsp;</td>

  </tr>

  <tr>

    <td>&nbsp;</td>

    <td>&nbsp;</td>

  </tr>

  <tr>

    <td colspan="2"><font color="#ff9933" face="Arial, Helvetica, sans-serif"><strong><a href="http://www.cs.bowiestate.edu/sharad/Lab/index.html" target="_parent">Location 

  Based Sensor Network</a></strong></font></td>

  </tr>

  <tr>

    <td><a href="vrlab/rovio7.png"><img src="vrlab/rovio7.png" width="200" height="110" border="2"></a></td>

    <td><div align="justify"><font face="Arial, Helvetica, sans-serif">Building a location 
      
      sensing network using widely available off-the-shelf components, such as RFID 
      
      sensors and 802.11 stations. Provide a query interface to monitor the information. 
      
      The sensor network research will also focus on efficient video/image data delivery 
      
      and real-time visual surveillance. The hardware involves a mobile base station 
      
      mounted on a robot, video cameras, and various sensors. The network prototypes 
      
    and data access schemes can be simulated in NS2 simulators.</font></div></td>

  </tr>

  <tr>

    <td>&nbsp;</td>

    <td>&nbsp;</td>

  </tr>

</table>

<p>&nbsp;</p>

<hr>

<p align="center"><font color="#ff9933" size="+3" face="Arial, Helvetica, sans-serif"><strong>Applications</strong></font></p>

<p><font color="#ff9933" face="Arial, Helvetica, sans-serif"><strong><a href="sim/fuzzy/ece1500.html" target="_parent">AvatarSim</a></strong></font></p>

<p align="justify"><font face="Arial, Helvetica, sans-serif">This research study 

  investigates modeling strategies to simulate human egress behavior in emergency 

  scenarios and represent them in a goal-finding computer application. Engineers 

  and planners have to often make decisions regarding how design will affect the 

  behavior of occupants. The proposed human behavior system integrates both artificial 

  intelligence and fuzzy logic parameters. </font></p>

<p align="center"><font face="Arial, Helvetica, sans-serif"><a href="sim/fuzzy/lecture.html" target="_parent"><img src="sim/a3.jpg" width="414" height="218" border="1"></a> 

  </font></p>

<p align="center"><font face="Arial, Helvetica, sans-serif">The left image above 

  is the Graphic User Interface of AvatarSim </font></p>

<p><font color="#ff9933" face="Arial, Helvetica, sans-serif"><strong><a href="mus/Museum/Assembly.WRL" target="_parent">Assemble 

  Room in Virtual Reality</a></strong></font></p>

<p align="justify"><font face="Arial, Helvetica, sans-serif">The viewpoint inside 

  the assembly room is animated to provide enhanced view during the assembly of 

  the car. This application can also be used to educate and increase awareness 

  of the progress of manufacturing in a class room setting. Also the assembly 

  room has far consequences than education purposes. It can be used for commercial 

  purposes also. For example the customers can enter the car manufacturing website 

  and virtually assemble their own car just as one can go and assemble their own 

  computer at www.dell.com.</font></p>

<p align="center"><font face="Arial, Helvetica, sans-serif"><a href="mus/Museum/Assembly.WRL" target="_parent"><img src="mus/a2.jpg" width="340" height="242" border="1"><img src="mus/a3.jpg" width="340" height="242" border="1"></a></font></p>

<p align="center"><font face="Arial, Helvetica, sans-serif">The images above are 

  views of the Assembly room where car parts are shown at the bottom for the users 

  to select and customize according to their own choice.</font></p>

<p><font color="#ff9933" face="Arial, Helvetica, sans-serif"><strong><a href="graphics/Thumbnails.html" target="_parent">Architectural 

  Walkthroughs</a></strong></font></p>

<p><font face="Arial, Helvetica, sans-serif">Interactive 3D graphics and animations 

  allow architects and clients to evaluate their design for usability, lighting, 

  and aesthetic appeal. It allows for prediction of potential flaws during early 

  part of design.</font></p>

<p align="center"><font face="Arial, Helvetica, sans-serif"><a href="graphics/Thumbnails.html" target="_parent"><img src="graphics/Rendering1.jpg" width="340" height="242"><img src="graphics/Rendering4.jpg" width="340" height="242"></a></font></p>

<p align="center"><font face="Arial, Helvetica, sans-serif">The images above show 

  architectural models with the use of Form Z and Lightscape.</font></p>

<p><font color="#ff9933" face="Arial, Helvetica, sans-serif"><strong><a href="brico.jpg">Bricolage 

  </a> </strong></font></p>

<p align="justify"><font face="Arial, Helvetica, sans-serif">The program designed 

  will be computer based and will take the appearance of a collage. The driving 

  question/central theme will be in the middle with pod connections radiating 

  off. These pods may hold information in the form of music, literature, movie 

  clips, and images. The connections made will be written and visible to the audience. 

  The software, Bricolage, is an empty collage. In the middle is the spot for 

  a driving question or central idea. Empty pods radiate from the central idea. 

  Students fill each pod with a multimedia element and make a written connection 

  that relates it back to the central idea. </font></p>

<p align="center"><font face="Arial, Helvetica, sans-serif"><a href="brico.jpg" target="_parent"><img src="brico.jpg" width="355" height="263" border="1"></a></font></p>

<p align="justify"><font face="Arial, Helvetica, sans-serif">Bricolage is written 

  in PHP and Flash and makes extensive use of HTML. Web applications no longer 

  exist exclusively in the realm of the Internet. The web browser has, in fact, 

  become the user interface of choice for growing numbers of enterprise functions, 

  greatly expanding the range and focus for the development of web-based solutions.</font></p>

<p>&nbsp;</p>

<p><font face="Arial, Helvetica, sans-serif"><a href="hill/graphics.htm" target="_parent"><strong>House 

  on the Hills (Made using OPEN GL Programming with GLut32 &amp;Glaux Library)</strong></a></font></p>

<p align="justify"><font face="Arial, Helvetica, sans-serif">'House on the Hills' 

  is an effort to create a simulation of a neighborhood in a mountainous, snowy 

  terrain using detailed polygons and objects. A unique 3-D camera perspective 

  assists in letting the user explore the environment. It consists of a 360-degree 

  mip-mapped skybox that encloses a curved, snowy textured surface, which in turn 

  holds a flat textured road that is blocked off on both ends.</font></p>

<p align="center"><a href="hill/graphics.htm"><img src="hill/19.gif" width="340" height="242" border="1"></a> 

  <a href="hill/graphics.htm"><img src="hill/7.gif" width="340" height="242" border="1"></a></p>

<p align="center"><font face="Arial, Helvetica, sans-serif">The image on the left 

  shows sky view with mip mapped skybox with texture mapped mountains and roads, 

  lamp posts, trees,car, trash can, letter box. The image on the right shows view 

  of animated swings, swing set and merry go round.</font></p>

<hr>

<p align="center"><font size="-1">Copyright &copy; Sharad Sharma., All Rights 

  Reserved</font></p>

</body>





<!-- Mirrored from webpages.eng.wayne.edu/~av8306/aboutme.htm by HTTrack Website Copier/3.x [XR&CO'2007], Wed, 22 Aug 2007 22:35:57 GMT -->

</html>



